{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917e7ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Threshold for categorizing as Allowed or Restricted\u001b[39;00m\n\u001b[0;32m     19\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"bd_model_test.h5\")\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset_path = r\"C:\\Users\\ASUS\\Downloads\\Fuzzy_match_results.csv\"\n",
    "test_data = pd.read_csv(test_dataset_path)\n",
    "test_data = test_data.drop(['Similarity (%)'], axis=1)\n",
    "\n",
    "# Extract features for prediction (excluding 'title' and 'similarity' columns)\n",
    "X_test = test_data.iloc[:, 1:].values\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Threshold for categorizing as Allowed or Restricted\n",
    "threshold = 0.5\n",
    "\n",
    "# Initialize lists for Allowed and Restricted foods\n",
    "allowed_food = []\n",
    "restricted_food = []\n",
    "\n",
    "# Categorize foods based on predictions\n",
    "for i in range(len(test_data)):\n",
    "    title = test_data.iloc[i, 0]\n",
    "    prediction = predictions[i][0]  # Assuming a single output neuron for binary classification\n",
    "\n",
    "    if prediction >= threshold:\n",
    "        allowed_food.append(\"Food name in Bengali\")\n",
    "    else:\n",
    "        restricted_food.append(\"Food name in Bengali\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Allowed food:\")\n",
    "for i, food in enumerate(allowed_food, start=1):\n",
    "    print(f\"{i}. {food}\")\n",
    "\n",
    "print(\"\\nRestricted food:\")\n",
    "for i, food in enumerate(restricted_food, start=1):\n",
    "    print(f\"{i}. {food}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed48f6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Food name in Bengali'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Food name in Bengali'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(predictions):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[1;32m---> 34\u001b[0m         allowed_food\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFood name in Bengali\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m         restricted_food\u001b[38;5;241m.\u001b[39mappend(test_data\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFood name in Bengali\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Food name in Bengali'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"bd_model_test.h5\")\n",
    "\n",
    "# Read the test dataset\n",
    "test_data_path = \"C:/Users/ASUS/Downloads/Fuzzy_match_results.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Drop the 'Similarity (%)' column from the test data\n",
    "test_data = test_data.drop(columns=['Similarity (%)'])\n",
    "test_data = test_data.drop(columns=['Food name in Bengali'])\n",
    "\n",
    "\n",
    "# Convert all columns to numeric type\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop NaN values\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Categorize foods into 'allowed food' and 'restricted food' based on predictions\n",
    "allowed_food = []\n",
    "restricted_food = []\n",
    "\n",
    "for i, pred in enumerate(predictions):\n",
    "    if pred >= threshold:\n",
    "        allowed_food.append(test_data.iloc[i][\"Food name in Bengali\"])\n",
    "    else:\n",
    "        restricted_food.append(test_data.iloc[i][\"Food name in Bengali\"])\n",
    "\n",
    "# Display the results\n",
    "print(\"Allowed Food:\")\n",
    "print(allowed_food)\n",
    "print(\"\\nRestricted Food:\")\n",
    "print(restricted_food)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556668f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 24ms/step\n",
      "Allowed Food:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 21, 22, 24, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 46, 47, 48, 49, 50, 53, 56, 57, 60, 63, 64, 65, 66, 69, 70, 71, 75, 76, 77, 78, 79, 81, 82, 88, 89, 90, 91, 92, 93, 95, 98, 99, 101, 104, 105, 106, 107, 108, 109, 110, 111, 113, 116, 117, 118, 119, 120, 121, 124, 125, 126, 127, 128, 130, 131, 132, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 154, 155, 156, 157, 158, 159, 162, 165, 167, 169, 170, 171, 173, 174, 175, 178, 179, 180]\n",
      "\n",
      "Restricted Food:\n",
      "[10, 15, 19, 20, 23, 25, 26, 27, 28, 29, 42, 44, 45, 51, 52, 54, 55, 58, 59, 61, 62, 67, 68, 72, 73, 74, 80, 83, 84, 85, 86, 87, 94, 96, 97, 100, 102, 103, 112, 114, 115, 122, 123, 129, 140, 146, 151, 152, 153, 160, 161, 163, 164, 166, 168, 172, 176, 177]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"bd_model_test.h5\")\n",
    "\n",
    "# Read the test dataset\n",
    "test_data_path = \"C:/Users/ASUS/Downloads/Fuzzy_match_results.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Drop the 'Similarity (%)' column from the test data\n",
    "test_data = test_data.drop(columns=['Similarity (%)'])\n",
    "test_data = test_data.drop(columns=['Food name in Bengali'])\n",
    "\n",
    "# Convert all columns to numeric type\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop NaN values\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Categorize foods into 'allowed food' and 'restricted food' based on predictions\n",
    "allowed_food = []\n",
    "restricted_food = []\n",
    "\n",
    "# Loop through predictions\n",
    "for i, pred in enumerate(predictions):\n",
    "    if pred >= threshold:\n",
    "        allowed_food.append(test_data.index[i])  # Use index as food name\n",
    "    else:\n",
    "        restricted_food.append(test_data.index[i])  # Use index as food name\n",
    "\n",
    "# Display the results\n",
    "print(\"Allowed Food:\")\n",
    "print(allowed_food)\n",
    "print(\"\\nRestricted Food:\")\n",
    "print(restricted_food)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0145ec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step\n",
      "Allowed Food:\n",
      "1. Misti alu, holdey\n",
      "2. Misti alu, lal khosa\n",
      "3. Misti alu, holdey, siddha, lobon chara\n",
      "4. Misti alu, Komola Sundori\n",
      "5. Misti alu, sada\n",
      "6. Doi, misti\n",
      "7. Misti alu, sada, siddha, lobon chara\n",
      "8. Gol alu siddha, lobon chara\n",
      "9. Misti alu, lal khosa, siddha lobon chara\n",
      "10. Apel, khosa soho\n",
      "11. Misti alu, Komola Sundori, siddha, lobon chara\n",
      "12. Alu siddha, lobon soho\n",
      "13. Bon alu siddha, lobon chara\n",
      "14. Jayitri, gura\n",
      "15. Mistikumrar bichi\n",
      "16. Angur, halka sobuj\n",
      "17. Bon alu, bivinno projati\n",
      "18. Nolen gur\n",
      "19. Kondense milk, Goru, chini soho\n",
      "20. Mistikumra siddha, lobon chara\n",
      "21. Lemon ghas\n",
      "22. Posto dana\n",
      "23. Holud\n",
      "24. Apel, khosa chara\n",
      "25. Rupchanda, sada, shutki\n",
      "26. Akher ross\n",
      "27. Mistikumra\n",
      "28. Hizlee badam\n",
      "29. Poddo gota, shukna\n",
      "30. Akhrot\n",
      "31. Amloki\n",
      "32. Fesha, shutki\n",
      "33. Kajuli\n",
      "34. China badam er tel\n",
      "35. Kancha pepe siddha, lobon chara\n",
      "36. Kancha kola siddha, lobon chara\n",
      "37. Sorpunti, kata chara\n",
      "38. Kod liver tel\n",
      "39. Nashpati\n",
      "40. Palm tel\n",
      "41. Golmorich\n",
      "42. Chela, Fulchela, shukna\n",
      "43. Likar cha\n",
      "44. Tiler tel\n",
      "45. Peyara, bivinno projati, kancha\n",
      "46. Tetul, paka\n",
      "47. Khailsa, kata chara, chokh soho\n",
      "48. Mayer dudh\n",
      "49. Gur, Khejur\n",
      "50. Motorshuti\n",
      "51. China badam\n",
      "52. Tisi\n",
      "53. Poddo gota, kancha\n",
      "54. Lebur khosa\n",
      "55. Kathal, paka\n",
      "56. Lebu, Kagoji\n",
      "57. Soybean tel\n",
      "58. Kancha kola\n",
      "59. Narikel dudh\n",
      "60. Pesta\n",
      "61. Mauri\n",
      "62. Methi\n",
      "63. Kochi taal er shas\n",
      "64. Sorishar tel\n",
      "65. Komol paniyo\n",
      "66. Darchini gura\n",
      "67. Vetkee, shutki\n",
      "68. Surjomukhi bij\n",
      "69. Narikel, shukna\n",
      "70. Dhonia\n",
      "71. Jayfol\n",
      "72. Atafol\n",
      "73. Khorma\n",
      "74. Kodbel\n",
      "75. Aam, Fazli, paka\n",
      "76. Payesh\n",
      "77. Kathal er bichi\n",
      "78. Sarisha\n",
      "79. Kola, Sagar, paka\n",
      "80. Aam, Langra, paka\n",
      "81. Bedana, paka, bichi soho\n",
      "82. Gur, Akh\n",
      "83. Nona ata\n",
      "84. Khejur, paka, taza\n",
      "85. Golapjam\n",
      "86. Sorpunti\n",
      "87. Tular bij er tel\n",
      "88. Cha pata\n",
      "89. Pan pata\n",
      "90. Dalda/Bonoshpati\n",
      "91. Coffee, dudh o chini soho\n",
      "92. Dudh cha\n",
      "93. Mushambee\n",
      "94. Futi, paka\n",
      "95. Taal, paka\n",
      "96. Chichinga\n",
      "97. Malta, paka\n",
      "98. Ghee, gorur\n",
      "99. Chini, sada\n",
      "100. Bangee, paka\n",
      "101. Khabar pani\n",
      "102. Til\n",
      "103. Ada\n",
      "104. Amra\n",
      "105. Poa, kata chara\n",
      "106. Elach\n",
      "107. Madar\n",
      "108. Boroi\n",
      "109. Lichu\n",
      "110. Gab, Bilati, paka\n",
      "111. Katla\n",
      "112. Potol\n",
      "113. Poneer\n",
      "114. Jhinga\n",
      "115. Chilgoza\n",
      "116. Narikel\n",
      "117. Labongo\n",
      "118. Kamranga\n",
      "119. Zambura\n",
      "120. Margarine\n",
      "121. Dumur, paka\n",
      "122. Jira\n",
      "\n",
      "Restricted Food:\n",
      "1. Macher peti (Katla,Mrigal, Rui)\n",
      "2. Mohiser dudh\n",
      "3. Macher gada (Katla,Mrigal, Rui) \n",
      "4. Koi, Thai, chokh soho\n",
      "5. Potol siddha, lobon chara\n",
      "6. Anaros, Joldugee, paka\n",
      "7. Boal, kata chara\n",
      "8. Koi, deshi, chokh soho\n",
      "9. Dheros siddha, lobon chara\n",
      "10. Dhone pata\n",
      "11. Chital, kata chara\n",
      "12. Makhon, nonta\n",
      "13. Kalojam\n",
      "14. Chagoler dudh\n",
      "15. Baking powder\n",
      "16. Kalbaush\n",
      "17. Shaldudh\n",
      "18. Tarmuz, lal, paka\n",
      "19. Common carp, kata chara\n",
      "20. Mola, chokh soho\n",
      "21. Murgi, buker mangsaw, chamra charano\n",
      "22. Fesha, Teli\n",
      "23. Chanda, ranga, chokh soho\n",
      "24. Hasher dim siddha, lobon chira\n",
      "25. Mayonnaise, nonta\n",
      "26. Daber pani\n",
      "27. Pudina pata\n",
      "28. Punti, Vadi punti, chokh soho,  kata chara\n",
      "29. Foli\n",
      "30. Gorur dudh, makhon tola/noniheen\n",
      "31. Ghol\n",
      "32. Gura dudh, Goru, noni soho\n",
      "33. Komolar ross\n",
      "34. Tengra, bivinno projati, chokh soho\n",
      "35. Gorur dudh, purno noni soho\n",
      "36. Soybean dudh\n",
      "37. Thankuni pata\n",
      "38. Punti, Vadi punti, chokh soho\n",
      "39. Jamrul\n",
      "40. Rui, kata chara\n",
      "41. Gura dudh, Goru, makhon tola/noniheen\n",
      "42. Kachki, bivinno projati\n",
      "43. Tatkini\n",
      "44. Kachki mach vaja\n",
      "45. Pepe, paka\n",
      "46. Anaros, paka\n",
      "47. Dewa\n",
      "48. Olua\n",
      "49. Bata\n",
      "50. Bacha\n",
      "51. Pabda\n",
      "52. Modhu\n",
      "53. Lobon\n",
      "54. Komola\n",
      "55. Coffee\n",
      "56. Tejpata\n",
      "57. Bel, paka\n",
      "58. Dhundul\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"bd_model_test.h5\")\n",
    "\n",
    "# Read the test dataset\n",
    "test_data_path = \"C:/Users/ASUS/Downloads/Fuzzy_match_results.csv\"\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Drop the 'Similarity (%)' column from the test data\n",
    "test_data = test_data.drop(columns=['Similarity (%)'])\n",
    "\n",
    "# Extract food names for reference\n",
    "food_names = test_data['Food name in Bengali']\n",
    "\n",
    "# Drop 'Food name in Bengali' column\n",
    "test_data = test_data.drop(columns=['Food name in Bengali'])\n",
    "\n",
    "# Convert all columns to numeric type\n",
    "test_data = test_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop NaN values\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Initialize lists for allowed and restricted foods\n",
    "allowed_food = []\n",
    "restricted_food = []\n",
    "\n",
    "# Loop through predictions and categorize foods\n",
    "for food_name, pred in zip(food_names, predictions):\n",
    "    if pred >= threshold:\n",
    "        allowed_food.append(food_name)\n",
    "    else:\n",
    "        restricted_food.append(food_name)\n",
    "\n",
    "# Display the results\n",
    "print(\"Allowed Food:\")\n",
    "for idx, food in enumerate(allowed_food, start=1):\n",
    "    print(f\"{idx}. {food}\")\n",
    "\n",
    "print(\"\\nRestricted Food:\")\n",
    "for idx, food in enumerate(restricted_food, start=1):\n",
    "    print(f\"{idx}. {food}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4832a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
